{"cells":[{"cell_type":"markdown","metadata":{"id":"EhgKFpWquuTU"},"source":["# Ajuste de curvas\n","\n","<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/a/a8/Regression_pic_assymetrique.gif\" width=\"400px\" height=\"300px\" />\n","\n","> El **ajuste de curvas** es el proceso de construir una curva (función), que sea el mejor ajuste a una serie de puntos. Las curvas ajustadas pueden ser usadas como asistencia en la visualización de datos, para inferir valores de una función donde no hay datos disponibles, y para resumir la relación entre variables.\n","\n","**Referencia**:\n","- https://en.wikipedia.org/wiki/Curve_fitting\n","___"]},{"cell_type":"markdown","metadata":{"id":"zIkALN-CuuTX"},"source":["## Problema básico\n","\n","<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg\" width=\"400px\" height=\"200px\" />\n","\n","Consideramos que tenemos un conjunto de n pares ordenados de datos $(x_i,y_i)$, para $i=1,2,3,\\dots,n$.\n","\n","### ¿Cuál es la recta que mejor se ajusta a estos datos?\n","Consideramos entonces ajustes de la forma $\\hat{f}(x) = \\beta_0+\\beta_1 x = \\left[1 \\quad x\\right]\\left[\\begin{array}{c} \\beta_0 \\\\ \\beta_1 \\end{array}\\right]=\\left[1 \\quad x\\right]\\boldsymbol{\\beta}$ (lineas rectas).\n","\n","Para decir '*mejor*', tenemos que definir algún sentido en que una recta se ajuste *mejor* que otra.\n","\n","**Mínimos cuadrados**: el objetivo es seleccionar los coeficientes $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^\\top$, de forma que la función evaluada en los puntos $x_i$ i.e.($\\hat{f}(x_i)$) aproxime los valores correspondientes $y_i$.\n","\n","La formulación por mínimos cuadrados, encuentra los $\\boldsymbol{\\beta}=\\left[\\beta_0 \\quad \\beta_1 \\right]^T$ que minimiza\n","$$\\sum_{i=1}^{n}(y_i-\\hat{f}(x_i))^2=\\sum_{i=1}^{n}(y_i-\\left[1 \\quad x_i\\right]\\boldsymbol{\\beta})^2=\\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2,$$\n","\n","donde $\\boldsymbol{y}=\\left[y_1,\\quad\\cdots\\quad, y_n\\right]^\\top$, y $\\boldsymbol{X}=\\left[\\begin{array}{ccc}1 & x_1\\\\ \\vdots & \\vdots \\\\ 1 & x_n\\end{array}\\right].$ Esto es,\n","\n","$$\\boldsymbol{\\beta}^{ls} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sIP8IYFNJndn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yD8kKyhMuuTY"},"source":["## Ajuste polinomial\n","\n","Ahora, considere el siguiente conjunto de datos..."]},{"cell_type":"markdown","metadata":{"id":"NCTRarqMuuTY"},"source":["## Generación de cualquier modelo\n","$$\n","\\beta_0x^0+\\beta_1x^1+\\beta_2x^2+\\dots+\\beta_nx^n.\n","$$\n","Generando el vector de potencias de $x$:\n","$$\n","\\left[x^0, x^1, \\dots, x^{n}\\right]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"BZQiEgNH6NIW"},"source":["El modelo es el producto punto entre el vector de potencias de $x$ y $\\beta$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4J-sRUuJndp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hLD0YWhzuuTY"},"source":["## Regularización\n","\n","Vimos que la solución de mínimos cuadrados es:\n","$$\\boldsymbol{\\beta}^{ls} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2.$$\n","\n","Sin embargo, si crecemos el orden del modelo hay overfitting y algunos coeficientes óptimos $\\boldsymbol{\\beta}$ crecen muchísimo. Que un coeficiente sea muy grande, significa que se le da mucha importancia a alguna característica (que quizá sea ruido... no sirve para predecir).\n","\n","La regularización consiste en penalizar la magnitud de los coeficientes $\\boldsymbol{\\beta}$ en el problema de optimización, para que no crezcan tanto."]},{"cell_type":"markdown","metadata":{"id":"EGYw12WbuuTY"},"source":["### Ridge\n","\n","$$\\boldsymbol{\\beta}^{ridge} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2 + \\lambda\\left|\\left|\\boldsymbol{\\beta}\\right|\\right|^2$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ94brm2Jndq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"SzZV_GaAuuTY"},"source":["### Lasso\n","\n","$$\\boldsymbol{\\beta}^{lasso} = \\arg \\min_{\\boldsymbol{\\beta}} \\left|\\left|\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta}\\right|\\right|^2 + \\lambda\\left|\\left|\\boldsymbol{\\beta}\\right|\\right|_1$$\n","\n","La norma 1 no es más que la suma de los valores absolutos de las componentes $\\left|\\left|\\boldsymbol{\\beta}\\right|\\right|_1=\\sum_{j=0}^m\\left|\\beta_j\\right|$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6B36-PDbJndq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XLE13YAruuTZ"},"source":["# Clasificación binaria\n","\n","Lo que veremos en esta clase son aspectos básicos de lo que se conoce técnicamente con muchos nombres sofisticados: aprendizaje de máquina (machine learning), clasificación con redes neuronales (neural networks), entre otros.\n","\n","**Referencia**\n","- https://es.coursera.org/learn/neural-networks-deep-learning\n","___"]},{"cell_type":"markdown","metadata":{"id":"qHRPuE1SuuTZ"},"source":["## Formulación del problema\n","\n","###  Idea básica\n","\n","<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg\" width=\"150px\" />\n","\n","Presentamos la idea básica de clasificación binaria mediante un ejemplo.\n","\n","Tenemos como *entrada* una imagen digital y como *salida* una etiqueta que identifica a esta imagen como el logo del ITESO (en cuyo caso la etiqueta toma el valor de uno '1') o no (en cuyo caso la etiqueta toma el valor de cero '0').\n","\n","A la salida la denotaremos $y$.\n","\n","**¿Cómo guarda las imágenes un computador?** Código de colores RGB.\n","\n","<font color = red>\n","$$R=\\left[\\begin{array}{cccc}255 & 124 & \\dots & 45\\\\ 235 & 224 & \\dots & 135\\\\ \\vdots & \\vdots & & \\vdots\\\\ 23 & 12 & \\dots & 242\\end{array}\\right]$$\n","</font>\n","<font color = green>\n","$$G=\\left[\\begin{array}{cccc}255 & 154 & \\dots & 42\\\\ 215 & 24 & \\dots & 145\\\\ \\vdots & \\vdots & & \\vdots\\\\ 0 & 112 & \\dots & 232\\end{array}\\right]$$\n","</font>\n","<font color = blue>\n","$$B=\\left[\\begin{array}{cccc}255 & 231 & \\dots & 145\\\\ 144 & 234 & \\dots & 35\\\\ \\vdots & \\vdots & & \\vdots\\\\ 5 & 52 & \\dots & 42\\end{array}\\right]$$\n","</font>\n","\n","Cada matriz tiene tamaño correspondiente con los pixeles de la imagen. Si la imagen se de $64px\\times 64px$, cada matriz será de $64\\times 64$.\n","\n","**¿Cómo podemos convertir entonces una imagen en una entrada?** Ponemos cada valor de cada matriz en un vector de características $\\boldsymbol{x}$:\n","\n","$$\\boldsymbol{x}=\\left[\\begin{array}{ccc} \\text{vec}R & \\text{vec}G & \\text{vec}B \\end{array}\\right]^T=\\left[\\begin{array}{ccccccccc} 255 & 124 & \\dots & 255 & 154 & \\dots & 255 & 231 & \\dots \\end{array}\\right]^T$$\n","\n","Entonces el problema de clasificación se puede resumir como dado un vector de entrada $\\boldsymbol{x}$ (en este caso un vector con las intensidades de rojo, verde y azul por pixel de una imagen), predecir si la etiqueta correspondiente $y$ toma el valor de $1$ o $0$ (si es logo del ITESO o no).\n","\n","### Notación\n","En adelante seguiremos la siguiente notación.\n","\n","Un ejemplo de entrenamiento se representa por la pareja ordenada $(\\boldsymbol{x},y)$, donde $\\boldsymbol{x}\\in\\mathbb{R}^n$ y $y\\in\\left\\lbrace0,1\\right\\rbrace$.\n","\n","Tendremos $m$ ejemplos de entrenamiento, de modo que nuestro conjunto de entrenamiento será $\\left\\lbrace(\\boldsymbol{x}^1,y^1),(\\boldsymbol{x}^2,y^2),\\dots,(\\boldsymbol{x}^m,y^m)\\right\\rbrace$.\n","\n","Por otra parte, para presentar de forma más compacta las entradas de entrenamiento, definimos la matriz\n","\n","$$\\boldsymbol{X}=\\left[\\begin{array}{c} {\\boldsymbol{x}^1}^T \\\\ {\\boldsymbol{x}^2}^T \\\\ \\vdots \\\\ {\\boldsymbol{x}^m}^T \\end{array}\\right]\\in\\mathbb{R}^{m\\times n},$$\n","\n","cuyas filas son los vectores de entrenamiento de entrada transpuestos, y el vector\n","\n","$$\\boldsymbol{Y}=\\left[\\begin{array}{c} y^1 \\\\ y^2 \\\\ \\vdots \\\\ y^m \\end{array}\\right]\\in\\mathbb{R}^{m},$$\n","\n","cuyas componentes son las etiquetas (salidas) de entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"I9HFtw4kuuTZ"},"source":["## Regresión logística\n","\n","La idea entonces es, dado un vector de características $\\boldsymbol{x}$ (quizá correspondiente a una imagen que queramos identificar como el logo del ITESO o no), queremos obtener una predicción $\\hat{y}$ que es nuestro estimado de $y$.\n","\n","Formalmente $\\hat{y}=P(y=1|\\boldsymbol{x})\\in\\left[0,1\\right]$...\n","\n","Los parámetros de regresión serán $\\boldsymbol{\\beta}=\\left[\\beta_0\\quad \\beta_1\\quad \\dots\\quad \\beta_n \\right]^T\\in\\mathbb{R}^{n+1}.$\n","\n","**Primera idea:** usar una regresor lineal\n","\n","$$\\hat{y}=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\dots+\\beta_nx_n=\\left[1\\quad \\boldsymbol{x}^T\\right]\\boldsymbol{\\beta}=\\boldsymbol{x}_a^T\\boldsymbol{\\beta},$$\n","\n","donde $\\boldsymbol{x}_a=\\left[1\\quad \\boldsymbol{x}^T \\right]^T\\in\\mathbb{R}^{n+1}$.\n","\n","¿Cuál es el problema? Que el producto punto $\\boldsymbol{\\beta}^T\\boldsymbol{x}_a$ no está entre $0$ y $1$.\n","\n","**Entonces,** pasamos el regresor lineal por una sigmoide (función logística)\n","\n","$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okEC_7KZJndr"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3KbeLj3FuuTa"},"source":["Notamos que:\n","- Si $z$ es grande, $\\sigma(z)=1$.\n","- Si $-z$ es grande, $\\sigma(z)=0$.\n","- $\\sigma(0)=0.5$.\n","\n","Finalmente...\n","\n","**Regresor logístico:** $\\hat{y}=\\sigma(\\boldsymbol{x}_a^T\\boldsymbol{\\beta})$.\n","\n","Para manejar todos los datos de entrenamiento, se define la matriz\n","\n","$$\\boldsymbol{X}_a=\\left[\\boldsymbol{1}_{m\\times 1}\\quad \\boldsymbol{X}\\right]=\\left[\\begin{array}{cc} 1 & {\\boldsymbol{x}^1}^T \\\\ 1 & {\\boldsymbol{x}^2}^T \\\\ \\vdots & \\vdots \\\\ 1 & {\\boldsymbol{x}^m}^T \\end{array}\\right]\\in\\mathbb{R}^{m\\times (n+1)}.$$\n","\n","Así,\n","\n","$$\\hat{\\boldsymbol{Y}}=\\left[\\begin{array}{c} \\hat{y}^1 \\\\ \\hat{y}^2 \\\\ \\vdots \\\\ \\hat{y}^m \\end{array}\\right]=\\sigma(\\boldsymbol{X}_a\\boldsymbol{\\beta})$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5OqEYDvJndr"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ffI3pEjduuTa"},"source":["## Funcional de costo\n","Ya que tenemos definida la forma de nuestro modelo clasificador, debemos **entrenar** los parámetros $\\boldsymbol{\\beta}$ con los ejemplos de entrenamiento.\n","\n","Es decir, dados  $\\left\\lbrace(\\boldsymbol{x}^1,y^1),(\\boldsymbol{x}^2,y^2),\\dots,(\\boldsymbol{x}^m,y^m)\\right\\rbrace$, queremos encontrar parámetros $\\boldsymbol{\\beta}$ tales que $\\hat{y}^i=\\sigma({\\boldsymbol{x}_a^i}^T\\boldsymbol{\\beta})\\approx y^i$ 'lo mejor posible'.\n","\n","Esto lo plantearemos como un problema de optimización.\n","\n","**Primera idea:** minimizar error cuadrático $\\min_{\\boldsymbol{\\beta}} \\frac{1}{m}\\sum_{i=1}^m (\\hat{y}^i-y^i)^2$. Problema de optimización *no convexo*.\n","\n","**Alternativa:** entonces, se buscó una función de modo que el problema de optimización fuera convexo. Esta es:\n","\n","$$\\min_{\\boldsymbol{\\beta}} \\frac{1}{m}\\sum_{i=1}^m -\\left(y^i\\log(\\hat{y}^i)+(1-y^i)\\log(1-\\hat{y}^i)\\right)$$\n","\n","No pretendemos explicar toda esta función. Pero sí podemos ganar algo de intuición de porqué la usamos. Fijemos un $i$ dentro del sumatorio y consideremos el término $-\\left(y^i\\log(\\hat{y}^i)+(1-y^i)\\log(1-\\hat{y}^i)\\right)$.\n","\n","- Si $y^i=1$, entonces lo que queremos minimzar es $-\\log(\\hat{y}^i)$. Es decir, queremos que $\\hat{y}^i=\\sigma({\\boldsymbol{x}_a^i}^T\\boldsymbol{\\beta})$ sea lo más grande posible, osea $1=y^i$.\n","- Si $y^i=0$, entonces lo que queremos minimzar es $-\\log(1-\\hat{y}^i)$. Es decir, queremos que $\\hat{y}^i=\\sigma({\\boldsymbol{x}_a^i}^T\\boldsymbol{\\beta})$ sea lo más pequeño posible, osea $0=y^i$.\n","\n","En cualquier caso, esta función objetivo cumple con lo requerido."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qcb7dQNJndr"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"S3hRj6yxuuTa"},"source":["**Ejemplo**\n","\n","El archivo `ex2data1.txt` contiene datos de puntajes de dos exámenes de admisión (1 y 2), y etiquetas de si el respectivo estudiante fue admitido o no a la universidad."]},{"cell_type":"markdown","metadata":{"id":"Fk0ZdqBPuuTa"},"source":["Variables de entrada:\n","$$\n","x_1 = \\mathrm{Examen1}, \\qquad\n","x_2 = \\mathrm{Examen2}\n","$$\n","\n","Variable de salida:\n","$$\n","y = \\mathrm{Admitido}\n","$$\n","\n","Modelo\n","$$\n","\\hat{y} = \\sigma(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fAjB6rKJndr"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"6aHYIYkmuuTa"},"source":["Construir un clasificador binario por regresión lineal logística."]},{"cell_type":"markdown","metadata":{"id":"MqzWoGQtuuTa"},"source":["$$\\min_{\\boldsymbol{\\beta}} \\frac{1}{m}\\sum_{i=1}^m -\\left(y^i\\log(\\hat{y}^i)+(1-y^i)\\log(1-\\hat{y}^i)\\right)$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JquxtjW8Jnds"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}